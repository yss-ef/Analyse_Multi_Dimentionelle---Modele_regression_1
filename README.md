# üìà Projet de R√©gression Lin√©aire Simple

Ce projet a √©t√© r√©alis√© dans le cadre du module d'**Analyse des Donn√©es Multidimensionnelles**. Il pr√©sente deux approches pour calculer les coefficients d'un mod√®le de r√©gression lin√©aire simple ($Y = aX + b$) √† partir de donn√©es fournies dans un fichier Excel.

1.  **M√©thode 1 : Descente du Gradient (Approche It√©rative)**
2.  **M√©thode 2 : √âquation Normale (Approche Matricielle)**

---
---

## M√©thode 1 : Descente du Gradient (Approche It√©rative)

Cette premi√®re approche utilise la **descente du gradient**, un algorithme d'optimisation qui minimise l'erreur quadratique moyenne de mani√®re it√©rative pour trouver les meilleurs coefficients.

### ‚ú® Fonctionnalit√©s

-   **Lecture de donn√©es** depuis un fichier Excel (`.xlsx`).
-   **Calcul it√©ratif** des coefficients : la pente `a` et l'ordonn√©e √† l'origine `b`.
-   **Visualisation des r√©sultats** avec Matplotlib, montrant la droite de r√©gression et la courbe de diminution de l'erreur.
-   **Param√®tres ajustables** comme le taux d'apprentissage et le nombre d'it√©rations.

### ‚úÖ Pr√©requis

-   **Pandas** : Pour la lecture et la manipulation des donn√©es.
-   **Matplotlib** : Pour la visualisation des graphiques.

Vous pouvez les installer avec la commande suivante :
```bash
pip install pandas matplotlib openpyxl
```
### üß† Explication de la M√©thode

La descente du gradient cherche √† trouver le minimum d'une fonction (ici, la fonction d'erreur) en suivant la direction de la pente la plus forte. Tel un randonneur cherchant le point le plus bas d'une vall√©e dans le brouillard, il proc√®de par petits pas successifs. La mise √† jour des coefficients se fait √† chaque it√©ration jusqu'√† ce qu'ils convergent vers les valeurs optimales.

---

## M√©thode 2 : √âquation Normale (Approche Matricielle)

Cette seconde approche utilise la m√©thode des moindres carr√©s via l'√©quation normale, qui s'appuie sur des op√©rations d'alg√®bre lin√©aire (matrices) pour trouver une solution directe et analytique.

### ‚ú® Fonctionnalit√©s

* Lecture de donn√©es depuis un fichier Excel (`.xlsx`).

* Calcul automatique des coefficients de la r√©gression : la pente `a` et l'ordonn√©e √† l'origine `b`.

* Impl√©mentation pure de la formule matricielle sans utiliser de biblioth√®ques de machine learning comme Scikit-learn.

* Affichage clair du mod√®le de r√©gression final.

### ‚úÖ Pr√©requis

* **Pandas** : Pour la lecture et la manipulation des donn√©es.

* **NumPy** : Pour les calculs num√©riques et matriciels.

Vous pouvez les installer avec la commande suivante :
```Bash
pip install pandas numpy openpyxl
```

### üöÄ Comment l'utiliser ?

1. üìù Pr√©parez votre fichier de donn√©es :

   * Cr√©ez un fichier Excel (par exemple, donnees.xlsx).

   * La premi√®re colonne doit contenir vos donn√©es pour la variable d√©pendante (Y).

   * La deuxi√®me colonne doit contenir vos donn√©es pour la variable ind√©pendante (X).

   * Le fichier ne doit pas contenir d'en-t√™tes.

2. üîß Modifiez le nom du fichier dans le script :

   * Ouvrez le fichier de script Python.

   * Modifiez la ligne chemin_fichier = 'donnees_projet.xlsx' pour indiquer le chemin de votre propre fichier.
  
3. ‚ñ∂Ô∏è Ex√©cutez le script :

   * Ouvrez un terminal dans le dossier du projet et lancez la commande suivante :
     ```Bash
     python ModRegression-1.py
     ```
4. üëÄ Consultez les r√©sultats :
    * Le script affichera la pente (a) et l'ordonn√©e √† l'origine (b) calcul√©es, ainsi que l'√©quation finale de votre mod√®le.
  
### üß† Explication de la M√©thode

Le calcul est bas√© sur l'√©quation normale, qui fournit une solution analytique au probl√®me des moindres carr√©s. La formule est la suivante :

$$\hat{\beta} = (X^T X)^{-1} X^T Y$$

O√π :

* $\hat{\beta} est le vecteur contenant les coefficients `b` (intercept) et `a` (pente).
* Y est le vecteur des valeurs de la variable d√©pendante.
* X est la matrice de design, compos√©e d'une colonne de 1 (pour l'intercept) et d'une colonne avec les valeurs de la variable ind√©pendante.

